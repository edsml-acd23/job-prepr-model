{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93bc6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b74fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0f541",
   "metadata": {},
   "source": [
    "# Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052a9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/Users/andrei/code/images/images/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a042024",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/Users/andrei/code/images/images/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f877c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"~/code/images/images/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b41ce",
   "metadata": {},
   "source": [
    "# Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e147432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the names of contents of the folder\n",
    "all_images = []\n",
    "y_train = []\n",
    "X_train = []\n",
    "for folder_path in os.listdir(train_path):\n",
    "    if not folder_path.startswith(\".\"):\n",
    "        for image_path in os.listdir(os.path.join(train_path, folder_path)):\n",
    "            img = load_img(os.path.join(os.path.join(train_path, folder_path), image_path), color_mode = \"grayscale\")\n",
    "            X_train.append(img_to_array(img))\n",
    "            y_train.append(os.path.basename(os.path.normpath(folder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe44d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a032ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c7907",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea9313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the names of contents of the folder\n",
    "all_images = []\n",
    "y_test = []\n",
    "X_test = []\n",
    "\n",
    "for folder_path in os.listdir(test_path):\n",
    "    if not folder_path.startswith(\".\"):\n",
    "        for image_path in os.listdir(os.path.join(test_path, folder_path)):\n",
    "            img = load_img(os.path.join(os.path.join(test_path, folder_path), image_path), color_mode = \"grayscale\")\n",
    "            X_test.append(img_to_array(img))\n",
    "            y_test.append(os.path.basename(os.path.normpath(folder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866f952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907912e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d757da",
   "metadata": {},
   "source": [
    "# Investigation and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf702f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6d65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd8f043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       0.248569\n",
       "neutral     0.172860\n",
       "sad         0.171333\n",
       "fear        0.142361\n",
       "angry       0.138545\n",
       "surprise    0.111204\n",
       "disgust     0.015128\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "548bd124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       0.258279\n",
       "neutral     0.172092\n",
       "sad         0.161194\n",
       "fear        0.144070\n",
       "angry       0.135862\n",
       "surprise    0.112794\n",
       "disgust     0.015709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8706227",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y_train_df.value_counts(normalize=True).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227f7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2485687519517019"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bdeff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 48, 48, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87ed713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7066, 48, 48, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666cf05",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf9106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd55cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c86ce5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshaped = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5dfb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshaped = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "792068fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = ohe.fit_transform(y_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ef0c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = ohe.transform(y_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd55d367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_angry', 'x0_disgust', 'x0_fear', 'x0_happy', 'x0_neutral',\n",
       "       'x0_sad', 'x0_surprise'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a7b2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ede91f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28821, 48, 48, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903a675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f7a4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle, y_shuffle = shuffle(X_train, y_train_cat, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b2aca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_shuffle[:3000, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95db4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample = y_shuffle[:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc489f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0fc0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ba38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Notice this cool new layer that \"pipe\" your rescaling within the architecture\n",
    "model.add(Rescaling(1./255, input_shape=(48, 48, 1)))\n",
    "\n",
    "# Lets add 3 convolution layers, with relatively large kernel size as our pictures are quite big too\n",
    "model.add(layers.Conv2D(16, kernel_size=5, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=2, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33263676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a045e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_sample, y_sample, batch_size = 32, epochs = 1000,\n",
    "          callbacks=[EarlyStopping(patience = 20, restore_best_weights= True, monitor = \"val_accuracy\", mode = \"max\")],\n",
    "         validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54ff63",
   "metadata": {},
   "source": [
    "# Fitting on all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cee7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle_all, y_shuffle_all = shuffle(X_train, y_train_cat, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7ec2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 11:40:22.833196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "# Notice this cool new layer that \"pipe\" your rescaling within the architecture\n",
    "model2.add(Rescaling(1./255, input_shape=(48, 48, 1)))\n",
    "\n",
    "# Lets add 3 convolution layers, with relatively large kernel size as our pictures are quite big too\n",
    "model2.add(layers.Conv2D(16, kernel_size=5, activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model2.add(layers.Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model2.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model2.add(layers.Conv2D(32, kernel_size=2, activation=\"relu\"))\n",
    "model2.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "935e3b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.8065 - accuracy: 0.2503 - val_loss: 1.7812 - val_accuracy: 0.2602\n",
      "Epoch 2/1000\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 1.7330 - accuracy: 0.2860 - val_loss: 1.6955 - val_accuracy: 0.3211\n",
      "Epoch 3/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.6286 - accuracy: 0.3508 - val_loss: 1.5999 - val_accuracy: 0.3690\n",
      "Epoch 4/1000\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 1.5370 - accuracy: 0.4024 - val_loss: 1.5608 - val_accuracy: 0.3967\n",
      "Epoch 5/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.4799 - accuracy: 0.4288 - val_loss: 1.4901 - val_accuracy: 0.4300\n",
      "Epoch 6/1000\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 1.4293 - accuracy: 0.4496 - val_loss: 1.4607 - val_accuracy: 0.4397\n",
      "Epoch 7/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.3918 - accuracy: 0.4619 - val_loss: 1.4285 - val_accuracy: 0.4470\n",
      "Epoch 8/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.3514 - accuracy: 0.4816 - val_loss: 1.4250 - val_accuracy: 0.4555\n",
      "Epoch 9/1000\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 1.3207 - accuracy: 0.4892 - val_loss: 1.3949 - val_accuracy: 0.4704\n",
      "Epoch 10/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.2979 - accuracy: 0.4988 - val_loss: 1.3655 - val_accuracy: 0.4756\n",
      "Epoch 11/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.2743 - accuracy: 0.5098 - val_loss: 1.3839 - val_accuracy: 0.4763\n",
      "Epoch 12/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.2580 - accuracy: 0.5196 - val_loss: 1.3741 - val_accuracy: 0.4886\n",
      "Epoch 13/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.2381 - accuracy: 0.5243 - val_loss: 1.3642 - val_accuracy: 0.4779\n",
      "Epoch 14/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.2232 - accuracy: 0.5326 - val_loss: 1.3431 - val_accuracy: 0.4886\n",
      "Epoch 15/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.2051 - accuracy: 0.5409 - val_loss: 1.3376 - val_accuracy: 0.4973\n",
      "Epoch 16/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.1901 - accuracy: 0.5454 - val_loss: 1.3521 - val_accuracy: 0.4869\n",
      "Epoch 17/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.1775 - accuracy: 0.5484 - val_loss: 1.3477 - val_accuracy: 0.4897\n",
      "Epoch 18/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.1674 - accuracy: 0.5557 - val_loss: 1.3489 - val_accuracy: 0.4954\n",
      "Epoch 19/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.1574 - accuracy: 0.5586 - val_loss: 1.3575 - val_accuracy: 0.4846\n",
      "Epoch 20/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.1437 - accuracy: 0.5636 - val_loss: 1.3571 - val_accuracy: 0.4982\n",
      "Epoch 21/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.1362 - accuracy: 0.5673 - val_loss: 1.3245 - val_accuracy: 0.4984\n",
      "Epoch 22/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.1284 - accuracy: 0.5684 - val_loss: 1.3304 - val_accuracy: 0.4990\n",
      "Epoch 23/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.1160 - accuracy: 0.5744 - val_loss: 1.3491 - val_accuracy: 0.4902\n",
      "Epoch 24/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.1074 - accuracy: 0.5743 - val_loss: 1.3488 - val_accuracy: 0.4949\n",
      "Epoch 25/1000\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 1.1000 - accuracy: 0.5803 - val_loss: 1.3521 - val_accuracy: 0.4942\n",
      "Epoch 26/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.0939 - accuracy: 0.5837 - val_loss: 1.3309 - val_accuracy: 0.4980\n",
      "Epoch 27/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.0899 - accuracy: 0.5823 - val_loss: 1.3609 - val_accuracy: 0.5001\n",
      "Epoch 28/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.0786 - accuracy: 0.5884 - val_loss: 1.3514 - val_accuracy: 0.5107\n",
      "Epoch 29/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0698 - accuracy: 0.5910 - val_loss: 1.3722 - val_accuracy: 0.4975\n",
      "Epoch 30/1000\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 1.0655 - accuracy: 0.5917 - val_loss: 1.3627 - val_accuracy: 0.4945\n",
      "Epoch 31/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0573 - accuracy: 0.5975 - val_loss: 1.3466 - val_accuracy: 0.5010\n",
      "Epoch 32/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0543 - accuracy: 0.5984 - val_loss: 1.3662 - val_accuracy: 0.4937\n",
      "Epoch 33/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0463 - accuracy: 0.6028 - val_loss: 1.3685 - val_accuracy: 0.5023\n",
      "Epoch 34/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0401 - accuracy: 0.6041 - val_loss: 1.3754 - val_accuracy: 0.4888\n",
      "Epoch 35/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 1.0370 - accuracy: 0.6058 - val_loss: 1.3813 - val_accuracy: 0.4897\n",
      "Epoch 36/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0303 - accuracy: 0.6084 - val_loss: 1.3516 - val_accuracy: 0.4996\n",
      "Epoch 37/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0277 - accuracy: 0.6088 - val_loss: 1.3940 - val_accuracy: 0.5008\n",
      "Epoch 38/1000\n",
      "721/721 [==============================] - 9s 12ms/step - loss: 1.0191 - accuracy: 0.6117 - val_loss: 1.3803 - val_accuracy: 0.5042\n",
      "Epoch 39/1000\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 1.0159 - accuracy: 0.6122 - val_loss: 1.3659 - val_accuracy: 0.4999\n",
      "Epoch 40/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0071 - accuracy: 0.6142 - val_loss: 1.3795 - val_accuracy: 0.5008\n",
      "Epoch 41/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 1.0087 - accuracy: 0.6156 - val_loss: 1.3858 - val_accuracy: 0.4963\n",
      "Epoch 42/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 1.0021 - accuracy: 0.6144 - val_loss: 1.3826 - val_accuracy: 0.4990\n",
      "Epoch 43/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9977 - accuracy: 0.6204 - val_loss: 1.4009 - val_accuracy: 0.5015\n",
      "Epoch 44/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9967 - accuracy: 0.6211 - val_loss: 1.4184 - val_accuracy: 0.4999\n",
      "Epoch 45/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9888 - accuracy: 0.6235 - val_loss: 1.3970 - val_accuracy: 0.5060\n",
      "Epoch 46/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9839 - accuracy: 0.6279 - val_loss: 1.4310 - val_accuracy: 0.4826\n",
      "Epoch 47/1000\n",
      "721/721 [==============================] - 11s 15ms/step - loss: 0.9857 - accuracy: 0.6237 - val_loss: 1.4018 - val_accuracy: 0.5006\n",
      "Epoch 48/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9737 - accuracy: 0.6293 - val_loss: 1.4294 - val_accuracy: 0.4982\n",
      "Epoch 49/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9722 - accuracy: 0.6270 - val_loss: 1.4706 - val_accuracy: 0.4758\n",
      "Epoch 50/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9721 - accuracy: 0.6335 - val_loss: 1.4142 - val_accuracy: 0.4881\n",
      "Epoch 51/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9668 - accuracy: 0.6300 - val_loss: 1.4334 - val_accuracy: 0.4994\n",
      "Epoch 52/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9598 - accuracy: 0.6347 - val_loss: 1.4474 - val_accuracy: 0.4892\n",
      "Epoch 53/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9568 - accuracy: 0.6367 - val_loss: 1.4550 - val_accuracy: 0.4852\n",
      "Epoch 54/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9542 - accuracy: 0.6371 - val_loss: 1.4507 - val_accuracy: 0.4879\n",
      "Epoch 55/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9522 - accuracy: 0.6368 - val_loss: 1.4580 - val_accuracy: 0.4951\n",
      "Epoch 56/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9443 - accuracy: 0.6434 - val_loss: 1.4369 - val_accuracy: 0.4874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9440 - accuracy: 0.6429 - val_loss: 1.4811 - val_accuracy: 0.4876\n",
      "Epoch 58/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9455 - accuracy: 0.6413 - val_loss: 1.4819 - val_accuracy: 0.4723\n",
      "Epoch 59/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9410 - accuracy: 0.6415 - val_loss: 1.5000 - val_accuracy: 0.4727\n",
      "Epoch 60/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9337 - accuracy: 0.6443 - val_loss: 1.4697 - val_accuracy: 0.4885\n",
      "Epoch 61/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9326 - accuracy: 0.6453 - val_loss: 1.5057 - val_accuracy: 0.4853\n",
      "Epoch 62/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9341 - accuracy: 0.6459 - val_loss: 1.4710 - val_accuracy: 0.4900\n",
      "Epoch 63/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.9277 - accuracy: 0.6471 - val_loss: 1.4824 - val_accuracy: 0.4905\n",
      "Epoch 64/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9246 - accuracy: 0.6464 - val_loss: 1.4869 - val_accuracy: 0.4789\n",
      "Epoch 65/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9176 - accuracy: 0.6490 - val_loss: 1.4846 - val_accuracy: 0.4912\n",
      "Epoch 66/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9190 - accuracy: 0.6513 - val_loss: 1.5125 - val_accuracy: 0.4916\n",
      "Epoch 67/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9164 - accuracy: 0.6521 - val_loss: 1.5230 - val_accuracy: 0.4873\n",
      "Epoch 68/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9123 - accuracy: 0.6534 - val_loss: 1.5149 - val_accuracy: 0.4902\n",
      "Epoch 69/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.9103 - accuracy: 0.6553 - val_loss: 1.4997 - val_accuracy: 0.4817\n",
      "Epoch 70/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9058 - accuracy: 0.6573 - val_loss: 1.5156 - val_accuracy: 0.4871\n",
      "Epoch 71/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9018 - accuracy: 0.6581 - val_loss: 1.5598 - val_accuracy: 0.4850\n",
      "Epoch 72/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.9030 - accuracy: 0.6553 - val_loss: 1.5107 - val_accuracy: 0.4945\n",
      "Epoch 73/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.8977 - accuracy: 0.6577 - val_loss: 1.5746 - val_accuracy: 0.4768\n",
      "Epoch 74/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.8940 - accuracy: 0.6579 - val_loss: 1.5351 - val_accuracy: 0.4810\n",
      "Epoch 75/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.8950 - accuracy: 0.6597 - val_loss: 1.5389 - val_accuracy: 0.4879\n",
      "Epoch 76/1000\n",
      "721/721 [==============================] - 10s 14ms/step - loss: 0.8912 - accuracy: 0.6629 - val_loss: 1.5445 - val_accuracy: 0.4791\n",
      "Epoch 77/1000\n",
      "721/721 [==============================] - 10s 13ms/step - loss: 0.8868 - accuracy: 0.6633 - val_loss: 1.6012 - val_accuracy: 0.4905\n",
      "Epoch 78/1000\n",
      "721/721 [==============================] - 9s 13ms/step - loss: 0.8888 - accuracy: 0.6615 - val_loss: 1.5543 - val_accuracy: 0.4895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167ebeaf0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_shuffle_all, y_shuffle_all, batch_size = 32, epochs = 1000,\n",
    "          callbacks=[EarlyStopping(patience = 50, restore_best_weights= True, monitor = \"val_accuracy\", mode = \"max\")],\n",
    "         validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaab9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8253e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3be88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32054afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ConfusionMatrixDisplay(confusion_matrix(np.argmax(y_test_cat, axis =1), np.argmax(y_pred, axis =1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b73c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5541897",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874b1e2",
   "metadata": {},
   "source": [
    "# Uploading a temp model to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "141fc186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccdbc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9d31dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Model = None,\n",
    "               params: dict = None,\n",
    "               metrics: dict = None) -> None:\n",
    "    \"\"\"\n",
    "    persist trained model, params and metrics\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # retrieve mlflow env params\n",
    "    mlflow_tracking_uri = \"https://mlflow.lewagon.ai\"\n",
    "    mlflow_experiment = \"[batch-960]-job_prepr_temp\"\n",
    "    mlflow_model_name = \"[batch-960]-job_prepr_temp\"\n",
    "\n",
    "    # configure mlflow\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name=mlflow_experiment)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.keras.log_model(keras_model=model,\n",
    "                                   artifact_path=\"model\",\n",
    "                                   keras_module=\"tensorflow.keras\",\n",
    "                                   registered_model_name=mlflow_model_name)\n",
    "\n",
    "    print(\"\\n✅ data saved to mlflow\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6f96f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/06 11:55:39 INFO mlflow.tracking.fluent: Experiment with name '[batch-960]-job_prepr_temp' does not exist. Creating a new experiment.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/lg/x7r61bz54jlf6d0nvwrlqd0m0000gn/T/tmp8whg0dcx/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/lg/x7r61bz54jlf6d0nvwrlqd0m0000gn/T/tmp8whg0dcx/model/data/model/assets\n",
      "Successfully registered model '[batch-960]-job_prepr_temp'.\n",
      "2022/09/06 11:55:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: [batch-960]-job_prepr_temp, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ data saved to mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model '[batch-960]-job_prepr_temp'.\n"
     ]
    }
   ],
   "source": [
    "save_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1513838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11684afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 12:56:31.463919: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('https://mlflow.lewagon.ai/')\n",
    "mlflow_model_name = '[batch-960]-job_prepr_temp'\n",
    "model_uri = f\"models:/{mlflow_model_name}/Production\"\n",
    "try:\n",
    "    model = mlflow.keras.load_model(model_uri=model_uri)\n",
    "except:\n",
    "    raise Exception(f'No model in Production on mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cebdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 48, 48, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 44, 44, 16)        416       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 32)          4128      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               3300      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,191\n",
      "Trainable params: 13,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d88919b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 48, 48, 1),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'rescaling_input'}},\n",
       "  {'class_name': 'Rescaling',\n",
       "   'config': {'name': 'rescaling',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 48, 48, 1),\n",
       "    'dtype': 'float32',\n",
       "    'scale': 0.00392156862745098,\n",
       "    'offset': 0.0}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 16,\n",
       "    'kernel_size': (5, 5),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (3, 3),\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (3, 3),\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (2, 2),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (3, 3),\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Flatten',\n",
       "   'config': {'name': 'flatten',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'data_format': 'channels_last'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 100,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 7,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba056e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
