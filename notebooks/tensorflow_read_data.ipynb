{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ce902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3802d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31002 files belonging to 8 classes.\n",
      "Using 24802 files for training.\n"
     ]
    }
   ],
   "source": [
    "training_data = image_dataset_from_directory(\n",
    "    'archive',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=(100, 100),\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "314214c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31002 files belonging to 8 classes.\n",
      "Using 6200 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_data = image_dataset_from_directory(\n",
    "    'archive',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=(100, 100),\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798f36df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 100, 100, 1), (None, 8)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3030749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb799b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Notice this cool new layer that \"pipe\" your rescaling within the architecture\n",
    "model.add(Rescaling(1./255, input_shape=(100, 100, 1)))\n",
    "\n",
    "# Lets add 3 convolution layers, with relatively large kernel size as our pictures are quite big too\n",
    "model.add(layers.Conv2D(16, kernel_size=5, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=2, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1de96812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa798555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "776/776 [==============================] - 125s 160ms/step - loss: 1.4616 - accuracy: 0.4077 - val_loss: 1.3432 - val_accuracy: 0.4705\n",
      "Epoch 2/200\n",
      "776/776 [==============================] - 130s 166ms/step - loss: 1.2847 - accuracy: 0.4974 - val_loss: 1.2390 - val_accuracy: 0.5158\n",
      "Epoch 3/200\n",
      "776/776 [==============================] - 128s 164ms/step - loss: 1.2016 - accuracy: 0.5312 - val_loss: 1.2050 - val_accuracy: 0.5323\n",
      "Epoch 4/200\n",
      "776/776 [==============================] - 135s 174ms/step - loss: 1.1426 - accuracy: 0.5583 - val_loss: 1.1991 - val_accuracy: 0.5297\n",
      "Epoch 5/200\n",
      "776/776 [==============================] - 139s 178ms/step - loss: 1.0956 - accuracy: 0.5799 - val_loss: 1.1335 - val_accuracy: 0.5674\n",
      "Epoch 6/200\n",
      "776/776 [==============================] - 139s 178ms/step - loss: 1.0550 - accuracy: 0.5960 - val_loss: 1.0883 - val_accuracy: 0.5910\n",
      "Epoch 7/200\n",
      "776/776 [==============================] - 142s 182ms/step - loss: 1.0229 - accuracy: 0.6118 - val_loss: 1.0804 - val_accuracy: 0.5889\n",
      "Epoch 8/200\n",
      "776/776 [==============================] - 151s 194ms/step - loss: 0.9949 - accuracy: 0.6220 - val_loss: 1.0808 - val_accuracy: 0.5944\n",
      "Epoch 9/200\n",
      "776/776 [==============================] - 140s 180ms/step - loss: 0.9672 - accuracy: 0.6331 - val_loss: 1.0798 - val_accuracy: 0.5944\n",
      "Epoch 10/200\n",
      "776/776 [==============================] - 135s 173ms/step - loss: 0.9457 - accuracy: 0.6418 - val_loss: 1.0986 - val_accuracy: 0.5905\n",
      "Epoch 11/200\n",
      "776/776 [==============================] - 130s 166ms/step - loss: 0.9315 - accuracy: 0.6505 - val_loss: 1.0830 - val_accuracy: 0.5913\n",
      "Epoch 12/200\n",
      "776/776 [==============================] - 130s 167ms/step - loss: 0.8996 - accuracy: 0.6644 - val_loss: 1.0616 - val_accuracy: 0.6031\n",
      "Epoch 13/200\n",
      "776/776 [==============================] - 136s 174ms/step - loss: 0.8797 - accuracy: 0.6672 - val_loss: 1.1029 - val_accuracy: 0.5931\n",
      "Epoch 14/200\n",
      "776/776 [==============================] - 164s 210ms/step - loss: 0.8648 - accuracy: 0.6760 - val_loss: 1.0900 - val_accuracy: 0.5889\n",
      "Epoch 15/200\n",
      "776/776 [==============================] - 164s 210ms/step - loss: 0.8428 - accuracy: 0.6851 - val_loss: 1.1011 - val_accuracy: 0.6006\n",
      "Epoch 16/200\n",
      "776/776 [==============================] - 147s 188ms/step - loss: 0.8233 - accuracy: 0.6932 - val_loss: 1.1094 - val_accuracy: 0.5950\n",
      "Epoch 17/200\n",
      "776/776 [==============================] - 138s 178ms/step - loss: 0.8021 - accuracy: 0.7006 - val_loss: 1.1107 - val_accuracy: 0.5981\n",
      "Epoch 18/200\n",
      "776/776 [==============================] - 120s 153ms/step - loss: 0.7860 - accuracy: 0.7076 - val_loss: 1.1328 - val_accuracy: 0.5929\n",
      "Epoch 19/200\n",
      "740/776 [===========================>..] - ETA: 5s - loss: 0.7688 - accuracy: 0.7115"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data, epochs = 200, validation_data=validation_data,\n",
    "      callbacks=[EarlyStopping(patience = 10, restore_best_weights= True, monitor = \"val_accuracy\", mode = \"max\")], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c636261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
